<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="None">
    
    <link rel="canonical" href="https://serre-lab.github.io/neural_harmonizer/">
    <link rel="shortcut icon" href="./img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Neural Harmonizer</title>
    <link href="./css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="./css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="./css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="./css/highlight.css">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="./js/jquery-3.2.1.min.js"></script>
    <script src="./js/bootstrap-3.3.7.min.js"></script>
    <script src="./js/highlight.pack.js"></script>
    
      <script src="./js/elasticlunr.min.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '.';
      var is_top_frame = (window === window.parent);
        
        var pageToc = [
          {title: "Summary of the Project", url: "#_top", children: [
          ]},
          {title: "Data Release", url: "#data-release", children: [
          ]},
          {title: "\ud83d\uddde\ufe0f Citation", url: "#citation", children: [
          ]},
        ];

    </script>
    <script src="./js/base.js"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>

<nav class="navbar wm-page-top-frame">
  <div class="container-fluid wm-top-container">
    
    <div class="wm-top-tool pull-right wm-vcenter">
      <form class="dropdown wm-vcentered" id="wm-search-form" action="./search.html">
        
        <button id="wm-search-show" class="btn btn-sm btn-default" type="submit"
          ><i class="fa fa-search" aria-hidden="true"></i></button>

        <div class="input-group input-group-sm wm-top-search">
          <input type="text" name="q" class="form-control" id="mkdocs-search-query" placeholder="Search" autocomplete="off">
          <span class="input-group-btn" role="search">
            
            <button class="btn btn-default dropdown-toggle collapse" data-toggle="dropdown" type="button"><span class="caret"></span></button>
            <ul id="mkdocs-search-results" class="dropdown-menu dropdown-menu-right"></ul>
            <button id="wm-search-go" class="btn btn-default" type="submit"><i class="fa fa-search" aria-hidden="true"></i></button>
          </span>
        </div>
      </form>
    </div>

    
    <div class="wm-top-tool wm-vcenter pull-right wm-small-left">
      <button id="wm-toc-button" type="button" class="btn btn-sm btn-default wm-vcentered"><i class="fa fa-th-list" aria-hidden="true"></i></button>
    </div>

    
    

    
    <a href="" class="wm-top-brand wm-top-link wm-vcenter">
      
        <img class="wm-top-logo" src="./assets/logo.jpg"/>
      
      <div class="wm-top-title">
        Neural Harmonizer<br>
        
      </div>
    </a>
  </div>
</nav>

  <div id="main-content" class="wm-page-top-frame">
    
<nav class="wm-toc-pane">
  
    <ul class="wm-toctree wm-toc-repo">
      <li class="wm-toc-li wm-toc-lev1">
      <a class="wm-article-link wm-toc-text" href="https://serre-lab.github.io/neural_harmonizer/">
        
        Serre-Lab
      </a>
      </li>
    </ul>
  <ul class="wm-toctree">
        <li class="wm-toc-li wm-toc-lev1 "><a href="" class="wm-article-link wm-toc-text">Home</a>
</li>
        <li class="wm-toc-li wm-toc-lev1 "><a href="results/" class="wm-article-link wm-toc-text">Results</a>
</li>
  </ul>
</nav>

    <div class="wm-content-pane">
      <iframe class="wm-article" name="article"></iframe>
    </div>
  </div>

<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="results/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="results/" class="btn btn-xs btn-link">
        Results
      </a>
    </div>
    
  </div>

    

    <div style="text-align:center" class="latex-font">
    <h1 style="text-align: rigth; font-weight: bold; color: inherit; margin-bottom: 0.2em"> Performance-optimized deep neural networks are evolving into worse models of inferotemporal visual cortex
 </h1>

    <span class="author" style="font-weight: bold"> Ivan Felipe Rodriguez*<sup>1</sup>, Drew Linsley*<sup>1</sup>,Thomas Fel<sup>1</sup>, Michael Arcaro<sup>2</sup>, Saloni Sharma<sup>3</sup>,  <br> Margaret Livingstone<sup>3</sup>, Thomas Serre<sup>1</sup> </span> <br>
    <span class="affiliations"> <sup>1</sup>Carney Institute for Brain Science, Brown University, Providence, RI 02912 </span> <br>
     <span class="affiliations"> <sup>2</sup> Department of Psychology, University of Pennsylvania, Philadelphia, PA 19104</span> <br>
      <span class="affiliations"> <sup>3</sup>Department of Neurobiology, Harvard Medical School, Boston, MA 02115 </span> <br>
    <span class="mono"> {ivan_felipe_rodriguez,drew_linsley,thomas_fel,thomas_serre}@brown.edu </span>
</div>

<p align="center">
  <a href=""><strong>Read the official paper ¬ª</strong></a>
  <br>
  <br>
  <a href="https://serre-lab.github.io/neural_harmonizer/results">Explore results</a>
  ¬∑
  <a href="https://github.com/serre-lab/neural_harmonizer">Github</a>
  ¬∑
  <a href="https://serre-lab.github.io/Harmonization/">Harmonize your model</a>
  ¬∑
  <a href="https://elifesciences.org/articles/53798">Recordings paper</a>
  ¬∑
  <a href="https://arxiv.org/abs/1805.08819">Click-me paper</a>
</p>

<p><img src="assets/qualitative.png" width="100%" align="center"></p>
<h2 id="summary-of-the-project">Summary of the Project</h2>
<p>One of the most impactful findings in computational neuroscience over the past decade is that the object recognition accuracy of deep neural networks (DNNs) correlates with their ability to predict neural responses to natural images in the inferotemporal (IT)  cortex (Yamins et al. 2014). This discovery supported the long-held theory that object recognition is a core objective of the visual cortex, and suggested that more accurate DNNs would serve as better models of IT neuron responses to images (Shrimp et al. 2020; Dicarlo et al. 2007). Since then, deep learning has undergone a revolution of scale: billion parameter-scale DNNs trained on billions of images are rivaling or outperforming humans at visual tasks including object recognition. Have today's DNNs become more accurate at predicting IT neuron responses to images as they have grown more accurate at object recognition?</p>
<p><img src="assets/majaj.gif" width="100%" align="center"></p>
<p>Surprisingly, across three independent experiments, we find that this is not the case. DNNs have become progressively worse models of IT as their accuracy has increased on ImageNet. To understand why DNNs experience this trade-off and evaluate if they are still an appropriate paradigm for modeling the visual system, we turn to recordings of IT that capture spatially resolved maps of neuronal activity elicited by natural images (Arcaro,2020). These neuronal activity maps reveal that DNNs trained on ImageNet learn to rely on different visual features than those encoded by IT and that this problem worsens as their accuracy increases. We successfully resolved this issue with the \emph{neural harmonizer}, a plug-and-play training routine for DNNs that aligns their learned representations with humans (Fel et al. 2020). Our results suggest that harmonized DNNs break the trade-off between ImageNet accuracy and neural prediction accuracy that assails current DNNs and offer a path to more accurate models of biological vision. Our work indicates that the standard approach for modeling IT with task-optimized DNNs needs revision, and other biological constraints, including human psychophysics data, are needed to accurately reverse-engineer the visual cortex.
<img src="assets/data.png" width="40%" align="right"></p>
<h2 id="data-release">Data Release</h2>
<p>We are realising the stimuli and the neural recordings that were used for this project. To obtain the files, the easiest way is to run the following code: </p>
<pre><code class="language-python">from neural_harmonizer.data import Neural_dataset

clickme_ds = Neural_dataset()
</code></pre>
<p>This would automatically download the data and organize it for your use! </p>
<h2 id="citation">üóûÔ∏è Citation</h2>
<p>If you use or build on our work as part of your workflow in a scientific publication, please consider citing the <a href="">official paper</a>:</p>
<p>Moreover, this paper relies heavily on previous work from the Lab, notably <a href="https://arxiv.org/abs/1805.08819">Learning What and Where to Attend</a> where the ambitious ClickMe dataset was collected. As well, as the   <strong>Harmonizer</strong> paper where we introduced <a href="https://arxiv.org/abs/2211.04533">Harmonization </a>:</p>
<pre><code>@article{fel2022aligning,
  title={Harmonizing the object recognition strategies of deep neural networks with humans},
  author={Fel, Thomas and Rodriguez, Ivan F and Linsley, Drew and Serre, Thomas},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022}
}
</code></pre>
<pre><code>@article{linsley2018learning,
  title={Learning what and where to attend},
  author={Linsley, Drew and Shiebler, Dan and Eberhardt, Sven and Serre, Thomas},
  journal={International Conference on Learning Representations (ICLR)},
  year={2019}
}
</code></pre>
<p>As well, the neural recordings  method, crucial for the development of this work: </p>
<pre><code>@article{Arcaro2020-ag,
  title    = &quot;The neurons that mistook a hat for a face&quot;,
  author   = &quot;Arcaro, Michael J and Ponce, Carlos and Livingstone, Margaret&quot;,
  journal  = &quot;Elife&quot;,
  year     =  2020,
  language = &quot;en&quot;
}
</code></pre>

  <br>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="results/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="results/" class="btn btn-xs btn-link">
        Results
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="container-fluid wm-page-content">
      <p>
        <a href="https://serre-lab.github.io/neural_harmonizer/">Serre-Lab</a>
      </p>
  <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>
<!--
MkDocs version : 1.4.3
Build Date UTC : 2023-06-05 20:22:40.974133+00:00
-->